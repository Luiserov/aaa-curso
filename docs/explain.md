---
title: Explicabilidad de modelos de aprendizaje supervisado 
subtitle: Curso Aprendizaje Automático Aplicado
layout: page
hero_image: https://github.com/mcd-unison/aaa-curso/raw/main/docs/img/intro-banner.jpeg
hero_darken: true
show_sidebar: false
---

## Material

1. Una muy pequeña entrada de la documentación de AWS que resuelve la duda de [Interpretability versus explainability](https://docs.aws.amazon.com/whitepapers/latest/model-explainability-aws-ai-ml/interpretability-versus-explainability.html)

1. Tutorial [*Explaining Machine Learning Predictions: State-of-the-art, Challenges, and Opportunities*](https://explainml-tutorial.github.io/neurips20) presentado en *NeurIPS 2020*

2. Libro [*Interpretable Machine Learning: A Guide for Making Black Box Models Explainable*](https://christophm.github.io/interpretable-ml-book/), un libro del 2023 sobre el tema.

3. Libro [*Explanatory Model Analysis: Explore, Explain, and Examine Predictive Models. With examples in R and Python.*](https://ema.drwhy.ai). El libro del grupo que creo DALEX.

4. La entrada de *Medium* [Machine Learning Model Interpretability and Explainability](https://towardsdatascience.com/model-interpretability-and-explainability-27fe31cc0688) dentro de TDS. Es una buena entrada con explicaciones sencillas.

5. La entrada de blog [Explainability and Auditability in ML: Definitions, Techniques, and Tools](https://neptune.ai/blog/explainability-auditability-ml-definitions-techniques-tools) de [Neptune.ai](https://neptune.ai). Muy buena y muy completa.

6. Un [curso corto de Kaggle](https://www.kaggle.com/learn/machine-learning-explainability) para aprender a usar algunas herramientas de explicabilidad (gráficas de dependencias y el métdo SHAP).

## Métodos


## Herramientas


1. [**InterpretML**](http://interpret.ml). Herramienta libre, desarrollada por Microsoft, pero en licencia de software libre.

2. [**AI Explainability 360**](http://aix360.mybluemix.net). Herramienta libre desarrollada por IBM, pero con licencia de softwate libre.

3. [**Alibi Explain**](https://github.com/SeldonIO/alibi). Librería de python de la empresa [Seldon](https://www.seldon.io) con licencia libre con herramientas para inspección y explicabilidad de modelos de aprendizaje automático. 

4. [**What-If Tool**](https://pair-code.github.io/what-if-tool/). Tensorflow desarrolló esta herramienta gráfica que permite probar el comportamiento de un modelo en tensorflow ante variaciones en las entradas.

5. [DALEX](https://dalex.drwhy.ai). Plataforma para R y para python para **XAI** (*explainable artificial intelligence*) desarrollado por un grupo de académicos de Varsovia, [MI<sup>2</sup>.AI](https://www.mi2.ai). Muy centrado en la equidad (*fairness*) de los modelos de aprendizaje. Es toda una propuesta de plataforma.



